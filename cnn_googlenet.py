# -*- coding: utf-8 -*-
"""cnn_googlenet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OUh4B3hTstfIn4c5xjaGR2yR9UeoMt_R
"""

import torch
from torch.utils.data import Dataset,DataLoader
import matplotlib.pyplot as plt
import torchvision

#loadinf data set
training_data = torchvision.datasets.CIFAR10(root='./data',train=True,download=True)
test_data = torchvision.datasets.CIFAR10(root='./data',train=False,download=True)

from torchvision.transforms import ToTensor
training_data = torchvision.datasets.CIFAR10(root='./data',train=True,transform=ToTensor())
test_data = torchvision.datasets.CIFAR10(root='./data',train=False,transform=ToTensor())

#creating data loader , we create them to use batch image and not give picture one by one to compiler so our run would become so much faster
train_loader = DataLoader(training_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=True)

#creating model
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
criterion = nn.CrossEntropyLoss()
model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)
op=model.eval()
optimizer = optim.SGD(op.parameters(),lr=0.001, momentum=0.9)

op=model.eval()
#using famouse models
for epoch in range(10):    #loop over the dataset multiple time
        running_loss=0.0
        for i, data in enumerate(train_loader, 0):
          #get the inputs; data is a list of[inputs, labels]
          inputs, labels = data

          #zero the parameter gradient
          optimizer.zero_grad()

          #forward + backward + optimize
          outputs = op(inputs)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()

          #print statistics
          running_loss +=loss.item()
        print("loss:",running_loss)
print('finishes training')

correct = 0
total = 0
# since we are not training, we do not need to calculate the gradient for our output
with torch.no_grad():
   for data in test_loader:
     images, labels = data
     #calculate outputs by running images through the network
     outputs = op(images)
     #the class with the highest energy is what we choose as prediction
     _,predicted= torch.max(outputs.data, 1)
     total += labels.size(0)
     correct += (predicted == labels).sum().item()
   print(f'Acuure=acy of the network on the 10000 test image: {100 * correct//total}%')